import nltk, string, fileinput, json, sys
from sklearn.feature_extraction.text import TfidfVectorizer

stemmer = nltk.stem.porter.PorterStemmer()
remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)

def stem_tokens(tokens):
    return [stemmer.stem(item) for item in tokens]

def normalize(text):
    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))

vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english', use_idf=True)

def cosine_sim(text1, text2):
    tfidf = vectorizer.fit_transform([text1, text2])
    return  ((tfidf * tfidf.T).A)[0,1]

if __name__ == '__main__':

    seed_text = ""
    tweets = []

    first = True
    for line in fileinput.input():

        if first:
            seed_text = line
        else:
            tweets.append(json.loads(line))

    scores = [(cosine_sim(tweet['text'], seed_text), tweet) for tweet in tweets]
    scores.sort(key=lambda x: x[0], reverse=True)
    sys.stdout.write(json.dumps(scores))
